{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13849f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils.data_utils import drop_id\n",
    "from src.utils.validators import test_pipeline_artifacts, generate_sample_requests\n",
    "\n",
    "from src.utils.feature_eng_utils import (\n",
    "    min_max_scale,\n",
    "    simple_label_encoding,\n",
    "    one_hot_encoding,\n",
    "    get_binary_features,\n",
    "    get_categorical_features,\n",
    "    k_highest_features,\n",
    "    random_forest_feature_selection\n",
    ")\n",
    "\n",
    "from src.utils.graph_utils import display_correlation\n",
    "from src.utils.notebook_setup import setup_notebook_environment\n",
    "\n",
    "# Quick setup\n",
    "dbs, logger = await setup_notebook_environment()\n",
    "\n",
    "# Now ready to work\n",
    "logger.info(\"=== COMPREHENSIVE FEATURE SELECTION ===\")\n",
    "\n",
    "# Checking Silver Layer\n",
    "silver_data = await dbs.get_silver_data()\n",
    "silver_data_df = pd.DataFrame(silver_data)\n",
    "silver_data_df = drop_id(silver_data_df)\n",
    "\n",
    "silver_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f77231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Encoding\n",
    "logger.info(\"Categorical Encoding using Label Encoder\")\n",
    "\n",
    "# Get binary features (both boolean and 2-value categorical)\n",
    "binary_cols = get_binary_features(silver_data_df)\n",
    "logger.info(f\"Binary Columns to encode: {binary_cols}\")\n",
    "\n",
    "# Apply label encoding to binary features\n",
    "silver_data_df = simple_label_encoding(silver_data_df, binary_cols)\n",
    "\n",
    "# Get multi-class categorical features\n",
    "categorical_cols = get_categorical_features(silver_data_df, exclude_binary=True)\n",
    "logger.info(f\"Multi-class Categorical Columns: {categorical_cols}\")\n",
    "\n",
    "# Apply one-hot encoding to multi-class categorical features\n",
    "if categorical_cols:  # Only if there are multi-class categorical features\n",
    "    silver_data_df = one_hot_encoding(silver_data_df, categorical_cols)\n",
    "\n",
    "# Check final result\n",
    "logger.info(f\"Final dataset shape: {silver_data_df.shape}\")\n",
    "logger.info(f\"Final columns: {list(silver_data_df.columns)}\")\n",
    "logger.info(f\"Data types: {silver_data_df.dtypes.value_counts()}\")\n",
    "\n",
    "silver_data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f693eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data_df = min_max_scale(silver_data_df)\n",
    "logger.info(f\"shape: {silver_data_df.shape}\")\n",
    "silver_data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_correlation(silver_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38421305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all dataset_origin columns from one hot encoding, they are irrelevant\n",
    "silver_data_df.columns\n",
    "\n",
    "dataset_origin_col =  [col for col in silver_data_df.columns if 'dataset' in col]\n",
    "silver_data_df = silver_data_df.drop(dataset_origin_col, axis=1)\n",
    "logger.info(f\"shape: {silver_data_df.shape}\")\n",
    "silver_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d03759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Extract target variable FIRST (before feature selection)\n",
    "logger.info(\"=== EXTRACTING TARGET VARIABLE ===\")\n",
    "\n",
    "# Extract target before any feature selection\n",
    "y = silver_data_df['target'].copy()  # Save the target\n",
    "X = silver_data_df.drop('target', axis=1)  # Features without target\n",
    "\n",
    "logger.info(f\"Target variable shape: {y.shape}\")\n",
    "logger.info(f\"Features matrix shape: {X.shape}\")\n",
    "logger.info(f\"Target value counts:\\n{y.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb96c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== FEATURE SELECTION ===\")\n",
    "\n",
    "kbest_selected_features, kbest_rejected_features, kbest_scored_df = k_highest_features(\n",
    "    silver_data_df,  # Complete dataframe with target\n",
    "    target_col='target',  # Column name as string\n",
    "    k=15\n",
    ")\n",
    "\n",
    "rf_selected_features, rf_rejected_features, rf_scored_df = random_forest_feature_selection(\n",
    "    silver_data_df,  # Complete dataframe with target\n",
    "    target_col='target',  # Column name as string\n",
    "    k=15\n",
    ")\n",
    "\n",
    "logger.info(\"\\nFEATURES FROM SELECT K BEST\\n\")\n",
    "logger.info(f\"SelectKBest selected: {len(kbest_selected_features)} features\")\n",
    "logger.info(f\"RandomForest selected: {len(rf_selected_features)} features\")\n",
    "\n",
    "logger.info(\"\\nSELECTED FEATURES:\")\n",
    "logger.info(kbest_selected_features)\n",
    "logger.info(\"\\nREJECTED FEATURES:\")\n",
    "logger.info(kbest_rejected_features)\n",
    "logger.info(\"\\nSCORED FEATURES:\")\n",
    "kbest_scored_df.head(10)\n",
    "\n",
    "logger.info(\"\\nSELECTED FEATURES:\")\n",
    "logger.info(rf_selected_features)\n",
    "logger.info(\"\\nREJECTED FEATURES:\")\n",
    "logger.info(rf_rejected_features)\n",
    "logger.info(\"\\nSCORED FEATURES:\")\n",
    "rf_scored_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Convergent Features\n",
    "logger.info(\"=== CONVERGENT FEATURE SELECTION ===\")\n",
    "\n",
    "convergent_rejected = []\n",
    "clinical_baseline = ['age', 'sex']  # Always keep these\n",
    "\n",
    "# Find features rejected by both methods\n",
    "for feature in X.columns:  # Use X.columns, not silver_data_df.columns\n",
    "    if (feature in rf_rejected_features and \n",
    "        feature in kbest_rejected_features and\n",
    "        feature not in clinical_baseline and\n",
    "        feature != 'target'):  # Extra safety check\n",
    "        convergent_rejected.append(feature)\n",
    "\n",
    "logger.info(f\"Features rejected by BOTH methods: {convergent_rejected}\")\n",
    "\n",
    "# Features to keep (everything except convergent rejected)\n",
    "features_to_keep = [col for col in X.columns if col not in convergent_rejected]\n",
    "logger.info(f\"Final features to keep: {len(features_to_keep)} features\")\n",
    "logger.info(f\"Features: {features_to_keep}\")\n",
    "\n",
    "logger.info(\"=== EXTRACTING TARGET VARIABLE AFTER FEATURE SELECTION ===\")\n",
    "\n",
    "# Extract target after feature selection\n",
    "y = silver_data_df['target'].copy()\n",
    "X = silver_data_df.drop('target', axis=1)\n",
    "\n",
    "logger.info(f\"Target variable shape: {y.shape}\")\n",
    "logger.info(f\"Features matrix shape: {X.shape}\")\n",
    "logger.info(f\"Target value counts:\\n{y.value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== CREATING GOLD LAYER ===\")\n",
    "\n",
    "# Create X with selected features only\n",
    "X_selected = X[features_to_keep].copy()\n",
    "\n",
    "# Create Gold layer by combining selected features + target\n",
    "df_gold = X_selected.copy()\n",
    "df_gold['target'] = y  # Add target back\n",
    "\n",
    "logger.info(f\"Gold layer shape: {df_gold.shape}\")\n",
    "logger.info(f\"Gold layer columns: {list(df_gold.columns)}\")\n",
    "\n",
    "# Verify target was added correctly\n",
    "logger.info(f\"Target in Gold layer: {'target' in df_gold.columns}\")\n",
    "logger.info(f\"Gold layer target distribution:\\n{df_gold['target'].value_counts()}\")\n",
    "\n",
    "# Show sample of Gold layer\n",
    "logger.info(\"Gold layer sample:\")\n",
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c332b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== SAVING TO GOLD LAYER MONGODB ===\")\n",
    "\n",
    "# Convert to records for MongoDB\n",
    "gold_data = df_gold.to_dict('records')\n",
    "\n",
    "logger.info(f\"Converting {len(gold_data)} records to dict format\")\n",
    "logger.info(f\"Sample record keys: {list(gold_data[0].keys())}\")\n",
    "\n",
    "# Insert into Gold layer\n",
    "success = await dbs.insert_gold_data(gold_data)\n",
    "\n",
    "if success:\n",
    "    logger.info(\"Successfully saved Gold layer to MongoDB!\")\n",
    "    \n",
    "    # Verify by reading back\n",
    "    verification = await dbs.get_gold_data(limit=5)\n",
    "    logger.info(f\"Verification: Retrieved {len(verification)} records from Gold layer\")\n",
    "    \n",
    "    if verification:\n",
    "        logger.info(f\"Sample Gold record: {verification[0]}\")\n",
    "        verification_df = pd.DataFrame(verification)\n",
    "        logger.info(\"Verification sample:\")\n",
    "        verification_df.head(20)\n",
    "        logger.info(verification_df.info())\n",
    "        logger.info(verification_df.describe())\n",
    "        logger.info(f\"Verification shape: {verification_df.shape}\")\n",
    "else:\n",
    "    logger.error(\"Failed to save Gold layer to MongoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1da628",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"=== SAVING FEATURE ENGINEERING METADATA ===\")\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Create comprehensive metadata\n",
    "feature_metadata = {\n",
    "    'original_features': list(X.columns),\n",
    "    'selected_features': features_to_keep,\n",
    "    'convergent_rejected': convergent_rejected,\n",
    "    'selectkbest_selected': kbest_selected_features,\n",
    "    'rf_selected': rf_selected_features,\n",
    "    'clinical_protected': clinical_baseline,\n",
    "    'feature_counts': {\n",
    "        'original': len(X.columns),\n",
    "        'selected': len(features_to_keep),\n",
    "        'removed': len(convergent_rejected)\n",
    "    },\n",
    "    'gold_layer_shape': df_gold.shape,\n",
    "    'target_distribution': df_gold['target'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "\n",
    "with open('../models/feature_engineering_metadata.json', 'w') as f:\n",
    "    json.dump(feature_metadata, f)\n",
    "logger.info(\"Saved feature engineering metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"FEATURE ENGINEERING COMPLETE - SUMMARY\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "logger.info(f\"Original features: {len(X.columns)}\")\n",
    "logger.info(f\"Selected features: {len(features_to_keep)}\")\n",
    "logger.info(f\"Removed features: {len(convergent_rejected)}\")\n",
    "logger.info(f\"Gold layer shape: {df_gold.shape}\")\n",
    "logger.info(f\"Target preserved: {df_gold['target'].notna().all()}\")\n",
    "logger.info(f\"Data saved to MongoDB Gold collection\")\n",
    "logger.info(f\"Metadata saved for model training\")\n",
    "\n",
    "logger.info(f\"\\nRemoved features: {convergent_rejected}\")\n",
    "logger.info(f\"Final features: {features_to_keep}\")\n",
    "\n",
    "logger.info(\"\\nREADY FOR MODEL TRAINING!\")\n",
    "logger.info(\"Next: Run 04_model_training.ipynb\")\n",
    "\n",
    "# %%\n",
    "# OPTIONAL: Quick verification of Gold layer data\n",
    "logger.info(\"=== GOLD LAYER VERIFICATION ===\")\n",
    "\n",
    "logger.info(\"Data types in Gold layer:\")\n",
    "logger.info(df_gold.dtypes)\n",
    "\n",
    "logger.info(\"\\nNumerical feature ranges (should be [0,1] from min-max scaling):\")\n",
    "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "for col in numerical_features:\n",
    "    if col in df_gold.columns:\n",
    "        logger.info(f\"{col}: {df_gold[col].min():.3f} to {df_gold[col].max():.3f}\")\n",
    "\n",
    "logger.info(\"\\nTarget distribution:\")\n",
    "logger.info(df_gold['target'].value_counts())\n",
    "\n",
    "logger.info(\"Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save COMPLETE preprocessing pipeline that transforms:\n",
    "Raw API Input → Gold Layer Format (ready for model)\n",
    "\n",
    "This captures the ENTIRE Bronze → Silver → Gold transformation\n",
    "\"\"\"\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "logger.info(\"=== SAVING COMPLETE PREPROCESSING PIPELINE ===\")\n",
    "\n",
    "# IMPORTANT: We need to create and fit the transformers that the API will use\n",
    "# These should match exactly what was done in preprocessing steps\n",
    "\n",
    "# 1. CREATE AND SAVE SCALER (based on min_max_scale function)\n",
    "logger.info(\"Creating and saving scaler...\")\n",
    "\n",
    "# Get numerical columns (same as in min_max_scale function)\n",
    "numerical_cols = df_gold.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_cols = numerical_cols.drop('target')  # don't scale target\n",
    "\n",
    "# Create and fit scaler on the final gold data (without target)\n",
    "final_scaler = MinMaxScaler()\n",
    "X_gold_for_scaler = df_gold.drop('target', axis=1)  # Features only for fitting scaler\n",
    "\n",
    "# Fit scaler only on numerical columns\n",
    "scaler_data = X_gold_for_scaler[numerical_cols]\n",
    "final_scaler.fit(scaler_data)\n",
    "\n",
    "# Save the fitted scaler\n",
    "joblib.dump(final_scaler, '../models/preprocessing_scaler.pkl')\n",
    "logger.info(\"Saved fitted MinMaxScaler\")\n",
    "\n",
    "# 2. CREATE AND SAVE CATEGORICAL ENCODERS\n",
    "logger.info(\"Creating and saving categorical encoders...\")\n",
    "\n",
    "# Define categorical features based on preprocessing\n",
    "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "\n",
    "# Create encoders dictionary (these would have been fitted during Silver→Gold processing)\n",
    "categorical_encoders_final = {}\n",
    "\n",
    "# Note: Since the data is already encoded, we'll create a mapping based on typical encodings\n",
    "# In a real scenario, save the actual fitted encoders from the Silver layer processing\n",
    "\n",
    "# Create manual encoders that match data transformations\n",
    "manual_categorical_mappings = {\n",
    "    'sex': {'male': 1, 'female': 0, 'Male': 1, 'Female': 0, 'M': 1, 'F': 0},\n",
    "    'cp': {'typical_angina': 0, 'atypical_angina': 1, 'non_anginal_pain': 2, 'asymptomatic': 3},\n",
    "    'fbs': {'false': 0, 'true': 1, 'no': 0, 'yes': 1},\n",
    "    'restecg': {'normal': 0, 'ST-T abnormality': 1, 'LV hypertrophy': 2},\n",
    "    'exang': {'no': 0, 'yes': 1, 'false': 0, 'true': 1},\n",
    "    'slope': {'upsloping': 0, 'flat': 1, 'downsloping': 2},\n",
    "    'thal': {'normal': 0, 'fixed_defect': 1, 'reversible_defect': 2, 'unknown': 3}\n",
    "}\n",
    "\n",
    "# Save categorical encoders info\n",
    "joblib.dump(manual_categorical_mappings, '../models/categorical_encoders.pkl')\n",
    "logger.info(\"Saved categorical encoders mappings\")\n",
    "\n",
    "# 3. SAVE FINAL FEATURE INFORMATION\n",
    "logger.info(\"Saving feature information...\")\n",
    "\n",
    "final_feature_columns = features_to_keep  # From feature selection\n",
    "final_feature_info = {\n",
    "    'feature_columns': final_feature_columns,\n",
    "    'selected_features': features_to_keep,\n",
    "    'original_features': list(X.columns),  # Before feature selection\n",
    "    'convergent_rejected': convergent_rejected,\n",
    "    'categorical_features': [f for f in categorical_features if f in final_feature_columns],\n",
    "    'numerical_features': [f for f in numerical_cols if f in final_feature_columns],\n",
    "    'selectkbest_features': kbest_selected_features,\n",
    "    'random_forest_features': rf_selected_features\n",
    "}\n",
    "\n",
    "with open('../models/feature_columns.json', 'w') as f:\n",
    "    json.dump(final_feature_info, f, indent=2)\n",
    "logger.info(\"Saved feature column information\")\n",
    "\n",
    "# 4. SAVE COMPLETE PIPELINE METADATA\n",
    "logger.info(\"Saving complete pipeline metadata...\")\n",
    "\n",
    "complete_pipeline_metadata = {\n",
    "    'pipeline_version': '1.0.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'gold_layer_shape': df_gold.shape,\n",
    "    'final_feature_count': len(features_to_keep),\n",
    "    'complete_transformation_steps': [\n",
    "        # Bronze → Silver transformations (from notebook 02)\n",
    "        'Step 1: Handle missing values (median for numeric, mode for categorical)',\n",
    "        'Step 2: Handle impossible zeros (convert to NaN then impute)', \n",
    "        'Step 3: Convert categorical strings to numeric (label encoding)',\n",
    "        \n",
    "        # Silver → Gold transformations (from this notebook)\n",
    "        'Step 4: Apply binary label encoding',\n",
    "        'Step 5: Apply one-hot encoding for multi-class categories',\n",
    "        'Step 6: Apply MinMax scaling to numerical features',\n",
    "        'Step 7: Apply convergent feature selection (SelectKBest + RandomForest)',\n",
    "        'Step 8: Final column ordering for model input'\n",
    "    ],\n",
    "    'transformation_details': {\n",
    "        'missing_value_imputation': {\n",
    "            'numerical_strategy': 'median',\n",
    "            'categorical_strategy': 'mode',\n",
    "            'impossible_zero_handling': 'convert_to_nan_then_impute'\n",
    "        },\n",
    "        'categorical_encoding': {\n",
    "            'binary_method': 'label_encoding',\n",
    "            'multiclass_method': 'one_hot_encoding',\n",
    "            'categorical_features': [f for f in categorical_features if f in final_feature_columns]\n",
    "        },\n",
    "        'scaling': {\n",
    "            'method': 'MinMaxScaler',\n",
    "            'numerical_features': [f for f in numerical_cols if f in final_feature_columns],\n",
    "            'fitted_on_gold_data': True\n",
    "        },\n",
    "        'feature_selection': {\n",
    "            'method': 'convergent_selection',\n",
    "            'selectkbest_k': 15,\n",
    "            'random_forest_k': 15,\n",
    "            'protected_features': ['age', 'sex'],\n",
    "            'original_count': len(X.columns),\n",
    "            'selected_count': len(features_to_keep),\n",
    "            'removed_count': len(convergent_rejected)\n",
    "        }\n",
    "    },\n",
    "    'api_input_format': {\n",
    "        'accepts': ['numeric_encoded', 'string_categories', 'mixed'],\n",
    "        'expected_raw_features': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
    "        'final_features': final_feature_columns,\n",
    "        'output_shape': len(features_to_keep)\n",
    "    },\n",
    "    'validation_ranges': {\n",
    "        'age': {'min': 1, 'max': 120},\n",
    "        'trestbps': {'min': 80, 'max': 250}, \n",
    "        'chol': {'min': 100, 'max': 600},\n",
    "        'thalach': {'min': 60, 'max': 220},\n",
    "        'oldpeak': {'min': 0.0, 'max': 10.0},\n",
    "        'ca': {'min': 0, 'max': 4}\n",
    "    },\n",
    "    'data_summary': {\n",
    "        'training_samples': len(df_gold),\n",
    "        'target_distribution': df_gold['target'].value_counts().to_dict(),\n",
    "        'feature_types': {\n",
    "            'numerical': len([f for f in numerical_cols if f in final_feature_columns]),\n",
    "            'categorical': len([f for f in categorical_features if f in final_feature_columns])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../models/preprocessing_metadata.json', 'w') as f:\n",
    "    json.dump(complete_pipeline_metadata, f, indent=2)\n",
    "logger.info(\"Saved complete pipeline metadata\")\n",
    "\n",
    "# 5. SAVE SAMPLE API REQUESTS FOR TESTING\n",
    "logger.info(\"Creating sample API requests...\")\n",
    "generate_sample_requests()\n",
    "logger.info(\" Sample API requests created\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
