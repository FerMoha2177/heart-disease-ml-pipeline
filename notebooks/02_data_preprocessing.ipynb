{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils.data_utils import (\n",
    "    test_missing_bias,\n",
    "    get_missing_data_summary,\n",
    "    missing_by_dataset,\n",
    "    missing_by_outcome,\n",
    "    handle_impossible_zeros,\n",
    "    impute_missing_values,\n",
    ")\n",
    "\n",
    "from src.utils.data_utils import drop_id\n",
    "from src.utils.graph_utils import(\n",
    "    display_relative_histoplot,\n",
    "    display_histoplot,\n",
    "    display_multi_histoplot,\n",
    "    display_multi_boxplot,\n",
    "    display_categorical_plots,\n",
    "    display_boxplot,\n",
    "    display_scatterplot\n",
    ") \n",
    "from src.utils.notebook_setup import setup_notebook_environment\n",
    "\n",
    "# Quick setup\n",
    "dbs, logger = await setup_notebook_environment()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Now ready to work\n",
    "logger.info(\"Starting data preprocessing...\")\n",
    "\n",
    "# Checking Bronze Layer\n",
    "bronze_data = await dbs.get_bronze_data()\n",
    "bronze_data_df = pd.DataFrame(bronze_data)\n",
    "bronze_data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_histoplot(df=bronze_data_df, column_name='age', title='Age Distribution Overall')\n",
    "logger.info(f\"Mean: {bronze_data_df['age'].mean():.2f}\")\n",
    "logger.info(f\"Median: {bronze_data_df['age'].median():.2f}\")\n",
    "logger.info(f\"Mode: {bronze_data_df['age'].mode()[0]:.2f}\")\n",
    "\n",
    "display_relative_histoplot(df=bronze_data_df, x_column_name='age', hue_column_name='sex', title='Age Distribution by Sex')\n",
    "bronze_data_df['sex'].value_counts()\n",
    "\n",
    "# see age distribution by dataset\n",
    "display_relative_histoplot(bronze_data_df, 'age', 'dataset', 'Age Distribution by Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Duplicates\n",
    "bronze_data_df.duplicated().sum()\n",
    "\n",
    "if bronze_data_df.duplicated().sum() > 0:\n",
    "    bronze_data_df = bronze_data_df.drop_duplicates()\n",
    "    logger.info(\"Dropped duplicate rows\")\n",
    "else:\n",
    "    logger.info(\"No duplicate rows found\")\n",
    "\n",
    "# checking data info\n",
    "bronze_data_df.info()\n",
    "logger.info(bronze_data_df.info())\n",
    "\n",
    "# DROP COLUMNS\n",
    "bronze_data_df = bronze_data_df.drop(columns=['_id', \"id\"])\n",
    "\n",
    "# show dataframe\n",
    "bronze_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c2b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checing Categorical Columns\n",
    "cat_cols = bronze_data_df.select_dtypes(include=['object']).columns\n",
    "num_cols = bronze_data_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "logger.info(\"Unique value COUNT in categorical columns\")\n",
    "logger.info(bronze_data_df[cat_cols].nunique())\n",
    "\n",
    "logger.info(\"Unique values in categorical columns\")\n",
    "logger.info(f\"ca: {bronze_data_df['ca'].unique()[:bronze_data_df['ca'].nunique()]}\")\n",
    "logger.info(f\"thal: {bronze_data_df['thal'].unique()[:bronze_data_df['thal'].nunique()]}\")\n",
    "logger.info(f\"slope: {bronze_data_df['slope'].unique()[:bronze_data_df['slope'].nunique()]}\")\n",
    "\n",
    "# Check numerical columns\n",
    "logger.info(\"Unique values COUNT in numerical columns\")\n",
    "logger.info(bronze_data_df[num_cols].nunique())\n",
    "# Remove non-plotting columns\n",
    "cat_cols = [col for col in cat_cols if col not in ['_id', 'dataset']]\n",
    "num_cols = [col for col in num_cols if col not in ['id']]\n",
    "\n",
    "logger.info(\"Unique value COUNT in categorical columns\")\n",
    "logger.info(bronze_data_df[cat_cols].nunique())\n",
    "\n",
    "# Visualize Numerical Columns (histograms)\n",
    "if len(num_cols) > 6:\n",
    "    display_multi_histoplot(bronze_data_df, num_cols[:6])\n",
    "    if len(num_cols) > 6:\n",
    "        display_multi_histoplot(bronze_data_df, num_cols[6:])\n",
    "else:\n",
    "    display_multi_histoplot(bronze_data_df, num_cols)\n",
    "\n",
    "# Visualize Numerical Boxplots (fixed)\n",
    "display_multi_boxplot(bronze_data_df, num_cols, target_col='num')\n",
    "\n",
    "# Visualize Categorical Columns (use count plots instead)\n",
    "display_categorical_plots(bronze_data_df, cat_cols, target_col='num')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = get_missing_data_summary(bronze_data_df)\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Tests Missing Data to Determine MNAR or MAR Missingness\n",
    "\n",
    "# TRUE = Missing pattern correlates with heart disease outcome, most likely missing because of patient condition (sicker patients get more tests)\n",
    "\n",
    "missing_bias_df = pd.DataFrame(columns=['Column', 'MNAR from Chi-square test'])\n",
    "for col in bronze_data_df.columns:\n",
    "    missing_bias_df.loc[len(missing_bias_df)] = [col, test_missing_bias(bronze_data_df, col, 'num')]\n",
    "\n",
    "logger.info(\"Missing bias:\")\n",
    "missing_bias_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Tests Missing Data to Determine MNAR or MAR Missing by Dataset\n",
    "\n",
    "# TRUE = Different studies have different missing patterns, Different hospitals/studies had different protocols\n",
    "missing_by_dataset_df = pd.DataFrame(columns=['Column', 'MNAR FROM DATASET ORIGIN'])\n",
    "for col in bronze_data_df.columns:\n",
    "    missing_by_dataset_df.loc[len(missing_by_dataset_df)] = [col, missing_by_dataset(bronze_data_df, col)]\n",
    "\n",
    "logger.info(\"Missing by dataset:\")\n",
    "missing_by_dataset_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f09837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missingness by outcome\n",
    "\n",
    "missing_by_outcome_df = pd.DataFrame(columns=['Column', 'MNAR FROM OUTCOME'])\n",
    "for col in bronze_data_df.columns:\n",
    "    missing_by_outcome_df.loc[len(missing_by_outcome_df)] = [col, missing_by_outcome(bronze_data_df, col)]\n",
    "\n",
    "logger.info(\"Missing by outcome:\")\n",
    "missing_by_outcome_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target as required\n",
    "bronze_data_df['target'] = (bronze_data_df['num'] > 0).astype(int)\n",
    "# 0 = no heart disease, 1 = any heart disease\n",
    "\n",
    "# Drop original multi-class target  \n",
    "bronze_data_df = bronze_data_df.drop(columns=['num'])\n",
    "bronze_data_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca40ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Judging from the MNAR tests and the missing patterns, we can see that ca and thal values should be dropped\n",
    " - Medical knowledge confirms that 'ca' being fluoroscopy is an expensive and invasive test only order for most likely high risk paitents\n",
    " - Medical knowledge confirms that 'thal' being a stress test is only conducted when doctors suspect heart problems\n",
    " - TRUE across all tests indicated that Systematic, non-random missingness\n",
    " - 66.4% and 52.8% missing = Too much missing data\n",
    " - Missingness predicts outcome, so we should drop these columns\n",
    "\n",
    " Imputing with mean or mode would introdue bias!\n",
    "\"\"\"\n",
    "\n",
    "# Drop ca and thal columns\n",
    "logger.info(\"Dropping ca and thal columns!\")\n",
    "if 'ca' in bronze_data_df.columns and 'thal' in bronze_data_df.columns:\n",
    "    bronze_data_df = bronze_data_df.drop(columns=['ca', 'thal'])\n",
    "\n",
    "logger.info(bronze_data_df.shape)\n",
    "bronze_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef763f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Slope is the slope of the peak exercise ST segment. It refers to the excercise stress test and when its administered it can be a valuable test\n",
    "Now for the slope column ... there was about 33% missing data meaning that 66% of the data was complete. \n",
    "\n",
    "Stress test can be a valuable test, but it is not always administered. But even when its not administered, it can be an indicator that it was Not needed\n",
    "\n",
    "So Since \n",
    "\"\"\"\n",
    "\n",
    "# Create a new column for missing slope values\n",
    "bronze_data_df['slope'] = bronze_data_df['slope'].fillna('not_tested')\n",
    "logger.info(bronze_data_df.shape)\n",
    "bronze_data_df.head()\n",
    "\n",
    "\n",
    "# Find missing values again\n",
    "missing_values = get_missing_data_summary(bronze_data_df)\n",
    "logger.info(\"Missing values after handling slope missing values\")\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229dc411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Handle impossible zeros\n",
    "cleaned_df = handle_impossible_zeros(bronze_data_df)\n",
    "\n",
    "# 2. Impute all missing values (including new NaNs from zeros)\n",
    "imputed_df = impute_missing_values(cleaned_df)\n",
    "\n",
    "# 3. Verify no missing values remain : summing the null counts across all columns\n",
    "assert imputed_df.isnull().sum().sum() == 0, \"Still have missing values!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a715b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Step: Save cleaned data to Silver layer\n",
    "\n",
    "# Verify final data quality\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"FINAL SILVER LAYER DATA SUMMARY\")\n",
    "logger.info(\"=\" * 60)\n",
    "\n",
    "logger.info(f\"Final dataset shape: {imputed_df.shape}\")\n",
    "logger.info(f\"Missing values remaining: {imputed_df.isnull().sum().sum()}\")\n",
    "logger.info(f\"Target variable distribution:\\n{imputed_df['target'].value_counts()}\")\n",
    "\n",
    "# Show final columns\n",
    "logger.info(f\"Final columns: {list(imputed_df.columns)}\")\n",
    "\n",
    "# Save to Silver collection in MongoDB\n",
    "logger.info(\"Saving cleaned data to Silver layer...\")\n",
    "\n",
    "# Convert DataFrame to records for MongoDB\n",
    "silver_data = imputed_df.to_dict('records')\n",
    "\n",
    "# Insert into Silver collection\n",
    "success = await dbs.insert_silver_data(silver_data)\n",
    "\n",
    "if success:\n",
    "    logger.info(f\"Successfully saved {len(silver_data)} records to Silver layer\")\n",
    "    \n",
    "    # Verify the save\n",
    "    silver_count = await dbs.get_collection_count('silver')\n",
    "    logger.info(f\"Silver collection now contains: {silver_count} documents\")\n",
    "    \n",
    "    # Show sample of Silver data\n",
    "    sample_silver = await dbs.get_sample_records('silver', count=3)\n",
    "    logger.info(\"Sample Silver layer records:\")\n",
    "    for i, record in enumerate(sample_silver):\n",
    "        logger.info(f\"Record {i+1}: {record}\")\n",
    "        \n",
    "else:\n",
    "    logger.error(\"Failed to save data to Silver layer\")\n",
    "\n",
    "logger.info(\"Data preprocessing complete! Ready for feature engineering.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
