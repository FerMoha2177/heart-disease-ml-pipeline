{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import load as load_model\n",
    "import os\n",
    "from src.utils.evaluate_utils import evaluate_model, load_trained_models, clear_worse_models\n",
    "from src.utils.training_utils import prepare_data\n",
    "from src.utils.data_utils import drop_id\n",
    "import datetime\n",
    "\n",
    "# Quick setup\n",
    "from src.utils.notebook_setup import setup_notebook_environment\n",
    "dbs, logger = await setup_notebook_environment()\n",
    "\n",
    "logger.info(\"=== STARTING MODEL EVALUATION ===\")\n",
    "\n",
    "\n",
    "# LOAD DATA (same as 04)\n",
    "gold_data_from_db = await dbs.get_gold_data()\n",
    "gold_data_df = pd.DataFrame(gold_data_from_db)\n",
    "gold_data_df = drop_id(gold_data_df)\n",
    "\n",
    "# RECREATE THE SAME SPLIT (important!)\n",
    "X = gold_data_df.drop('target', axis=1)\n",
    "y = gold_data_df['target']\n",
    "X_train, X_test, y_train, y_test = prepare_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logger.info(f\"Loaded test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained models\n",
    "trained_models = load_trained_models()\n",
    "logger.info(f\"Loaded {len(trained_models)} trained models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ALL TRAINED MODELS\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    logger.info(f\"Evaluating {model_name}...\")\n",
    "    result = evaluate_model(model, X_test, y_test, model_name)\n",
    "    all_results.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "all_results_df = pd.DataFrame([\n",
    "    {k: v for k, v in result.items() if k != 'model'} \n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "logger.info(\"\\n=== MODEL COMPARISON ===\")\n",
    "logger.info(all_results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec732dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND BEST ONE\n",
    "best_model_idx = all_results_df['roc_auc'].idxmax()\n",
    "best_model_name = all_results_df.iloc[best_model_idx]['model_name']\n",
    "best_model = all_results[best_model_idx]['model']\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "logger.info(f\"ROC-AUC: {all_results_df.iloc[best_model_idx]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE BEST MODEL TO DISK!\n",
    "from joblib import dump as dump_model\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Clear worse models\n",
    "clear_worse_models(best_model_name)\n",
    "\n",
    "# Save the winner as the final production model\n",
    "dump_model(best_model, \"../models/heart_disease_classifier.joblib\")\n",
    "\n",
    "best_result = all_results_df.iloc[best_model_idx]\n",
    "\n",
    "\n",
    "# Construct metadata dictionary\n",
    "model_metadata = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"algorithm\": type(best_model).__name__,\n",
    "    \"features\": list(X.columns),\n",
    "    \"target\": \"target\",\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": best_result[\"accuracy\"],\n",
    "        \"precision\": best_result[\"precision\"],\n",
    "        \"recall\": best_result[\"recall\"],\n",
    "        \"f1_score\": best_result[\"f1_score\"],\n",
    "        \"roc_auc\": best_result[\"roc_auc\"]\n",
    "    },\n",
    "    \"training_data_size\": len(X_train),\n",
    "    \"test_data_size\": len(X_test)\n",
    "}\n",
    "\n",
    "# Save to model_metadata.json\n",
    "logger.info(\"SAVING MODEL METADATA\")   \n",
    "with open(\"../models/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "\n",
    "logger.info(f\"Saved final model: {best_model_name} as heart_disease_classifier.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
