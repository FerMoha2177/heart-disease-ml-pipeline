{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755d3173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 10:42:38,389 - api.services.database_service - INFO - Connected to MongoDB database: healthcare\n",
      "2025-07-25 10:42:38,504 - src.utils.notebook_setup - INFO - Database connected: True\n",
      "2025-07-25 10:42:38,505 - src.utils.notebook_setup - INFO - Database collections: ['heart_disease_gold', 'heart_disease_silver', 'heart_disease_bronze']\n",
      "2025-07-25 10:42:38,507 - src.utils.notebook_setup - INFO - Database collections count: 3\n",
      "2025-07-25 10:42:38,508 - src.utils.notebook_setup - INFO - === STARTING MODEL EVALUATION ===\n",
      "2025-07-25 10:42:39,275 - src.utils.training_utils - INFO - Training set: (14720, 16), Test set: (3680, 16)\n",
      "2025-07-25 10:42:39,276 - src.utils.notebook_setup - INFO - Loaded test set: (3680, 16)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import load as load_model\n",
    "import os\n",
    "from src.utils.evaluate_utils import evaluate_model, load_trained_models, clear_worse_models\n",
    "from src.utils.training_utils import prepare_data\n",
    "from src.utils.data_utils import drop_id\n",
    "\n",
    "# Quick setup\n",
    "from src.utils.notebook_setup import setup_notebook_environment\n",
    "dbs, logger = await setup_notebook_environment()\n",
    "\n",
    "logger.info(\"=== STARTING MODEL EVALUATION ===\")\n",
    "\n",
    "\n",
    "# LOAD DATA (same as 04)\n",
    "gold_data_from_db = await dbs.get_gold_data()\n",
    "gold_data_df = pd.DataFrame(gold_data_from_db)\n",
    "gold_data_df = drop_id(gold_data_df)\n",
    "\n",
    "# RECREATE THE SAME SPLIT (important!)\n",
    "X = gold_data_df.drop('target', axis=1)\n",
    "y = gold_data_df['target']\n",
    "X_train, X_test, y_train, y_test = prepare_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logger.info(f\"Loaded test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca6607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 10:42:39,287 - src.utils.evaluate_utils - INFO - Loaded model: LogisticRegression\n",
      "2025-07-25 10:42:39,288 - src.utils.notebook_setup - INFO - Loaded 1 trained models\n"
     ]
    }
   ],
   "source": [
    "# load the trained models\n",
    "trained_models = load_trained_models()\n",
    "logger.info(f\"Loaded {len(trained_models)} trained models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e92b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 10:42:39,298 - src.utils.notebook_setup - INFO - Evaluating LogisticRegression...\n",
      "2025-07-25 10:42:39,322 - src.utils.evaluate_utils - INFO - \n",
      "LogisticRegression Evaluation Results:\n",
      "2025-07-25 10:42:39,323 - src.utils.evaluate_utils - INFO - Accuracy: 0.8122\n",
      "2025-07-25 10:42:39,326 - src.utils.evaluate_utils - INFO - Precision: 0.8195\n",
      "2025-07-25 10:42:39,327 - src.utils.evaluate_utils - INFO - Recall: 0.8472\n",
      "2025-07-25 10:42:39,329 - src.utils.evaluate_utils - INFO - F1-Score: 0.8331\n",
      "2025-07-25 10:42:39,330 - src.utils.evaluate_utils - INFO - ROC-AUC: 0.8886\n",
      "2025-07-25 10:42:39,332 - src.utils.notebook_setup - INFO - \n",
      "=== MODEL COMPARISON ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model_name  accuracy  precision  recall  f1_score  roc_auc\n",
      "0  LogisticRegression    0.8122     0.8195  0.8472    0.8331   0.8886\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE ALL TRAINED MODELS\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    logger.info(f\"Evaluating {model_name}...\")\n",
    "    result = evaluate_model(model, X_test, y_test, model_name)\n",
    "    all_results.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "all_results_df = pd.DataFrame([\n",
    "    {k: v for k, v in result.items() if k != 'model'} \n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "logger.info(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(all_results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec732dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 10:42:39,348 - src.utils.notebook_setup - INFO - \n",
      "=== BEST MODEL: LogisticRegression ===\n",
      "2025-07-25 10:42:39,351 - src.utils.notebook_setup - INFO - ROC-AUC: 0.8886\n",
      "2025-07-25 10:42:39,353 - src.utils.evaluate_utils - INFO - Removing worse model: LogisticRegression_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "# FIND BEST ONE\n",
    "best_model_idx = all_results_df['roc_auc'].idxmax()\n",
    "best_model_name = all_results_df.iloc[best_model_idx]['model_name']\n",
    "best_model = all_results[best_model_idx]['model']\n",
    "\n",
    "logger.info(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "logger.info(f\"ROC-AUC: {all_results_df.iloc[best_model_idx]['roc_auc']:.4f}\")\n",
    "\n",
    "# Delete the others from disk!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659d2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 10:42:39,427 - src.utils.notebook_setup - INFO - Saved final model: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# SAVE BEST MODEL TO DISK!\n",
    "from joblib import dump as dump_model\n",
    "\n",
    "# Save the winner as the final production model\n",
    "dump_model(best_model, \"../models/heart_disease_classifier.joblib\")\n",
    "clear_worse_models(best_model_name)\n",
    "logger.info(f\"Saved final model: {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
