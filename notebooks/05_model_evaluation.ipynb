{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755d3173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:22:34,715 - api.services.database_service - INFO - Connected to MongoDB database: healthcare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:22:34,720 - src.utils.notebook_setup - INFO - Database connected: True\n",
      "2025-07-25 22:22:34,722 - src.utils.notebook_setup - INFO - Database collections: ['heart_disease_silver', 'heart_disease_bronze', 'heart_disease_gold']\n",
      "2025-07-25 22:22:34,724 - src.utils.notebook_setup - INFO - Database collections count: 3\n",
      "2025-07-25 22:22:34,726 - src.utils.notebook_setup - INFO - === STARTING MODEL EVALUATION ===\n",
      "2025-07-25 22:22:34,916 - src.utils.training_utils - INFO - Training set: (5152, 16), Test set: (1288, 16)\n",
      "2025-07-25 22:22:34,919 - src.utils.notebook_setup - INFO - Loaded test set: (1288, 16)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import load as load_model\n",
    "import os\n",
    "from src.utils.evaluate_utils import evaluate_model, load_trained_models, clear_worse_models\n",
    "from src.utils.training_utils import prepare_data\n",
    "from src.utils.data_utils import drop_id\n",
    "import datetime\n",
    "\n",
    "# Quick setup\n",
    "from src.utils.notebook_setup import setup_notebook_environment\n",
    "dbs, logger = await setup_notebook_environment()\n",
    "\n",
    "logger.info(\"=== STARTING MODEL EVALUATION ===\")\n",
    "\n",
    "\n",
    "# LOAD DATA (same as 04)\n",
    "gold_data_from_db = await dbs.get_gold_data()\n",
    "gold_data_df = pd.DataFrame(gold_data_from_db)\n",
    "gold_data_df = drop_id(gold_data_df)\n",
    "\n",
    "# RECREATE THE SAME SPLIT (important!)\n",
    "X = gold_data_df.drop('target', axis=1)\n",
    "y = gold_data_df['target']\n",
    "X_train, X_test, y_train, y_test = prepare_data(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logger.info(f\"Loaded test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca6607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:22:40,387 - src.utils.evaluate_utils - INFO - Loaded model: SVM\n",
      "2025-07-25 22:22:40,389 - src.utils.evaluate_utils - INFO - Loaded model: Logistic Regression\n",
      "2025-07-25 22:22:40,444 - src.utils.evaluate_utils - INFO - Loaded model: Random Forest\n",
      "2025-07-25 22:22:40,450 - src.utils.evaluate_utils - INFO - Loaded model: XGBoost\n",
      "2025-07-25 22:22:40,452 - src.utils.notebook_setup - INFO - Loaded 4 trained models\n"
     ]
    }
   ],
   "source": [
    "# load the trained models\n",
    "trained_models = load_trained_models()\n",
    "logger.info(f\"Loaded {len(trained_models)} trained models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e92b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-25 22:22:55,576 - src.utils.notebook_setup - INFO - Evaluating SVM...\n",
      "2025-07-25 22:22:55,859 - src.utils.evaluate_utils - INFO - \n",
      "SVM Evaluation Results:\n",
      "2025-07-25 22:22:55,864 - src.utils.evaluate_utils - INFO - Accuracy: 0.8393\n",
      "2025-07-25 22:22:55,865 - src.utils.evaluate_utils - INFO - Precision: 0.8504\n",
      "2025-07-25 22:22:55,866 - src.utils.evaluate_utils - INFO - Recall: 0.8612\n",
      "2025-07-25 22:22:55,867 - src.utils.evaluate_utils - INFO - F1-Score: 0.8557\n",
      "2025-07-25 22:22:55,868 - src.utils.evaluate_utils - INFO - ROC-AUC: N/A\n",
      "2025-07-25 22:22:55,869 - src.utils.notebook_setup - INFO - Evaluating Logistic Regression...\n",
      "2025-07-25 22:22:55,894 - src.utils.evaluate_utils - INFO - \n",
      "Logistic Regression Evaluation Results:\n",
      "2025-07-25 22:22:55,895 - src.utils.evaluate_utils - INFO - Accuracy: 0.8005\n",
      "2025-07-25 22:22:55,896 - src.utils.evaluate_utils - INFO - Precision: 0.8089\n",
      "2025-07-25 22:22:55,898 - src.utils.evaluate_utils - INFO - Recall: 0.8373\n",
      "2025-07-25 22:22:55,899 - src.utils.evaluate_utils - INFO - F1-Score: 0.8229\n",
      "2025-07-25 22:22:55,900 - src.utils.evaluate_utils - INFO - ROC-AUC: 0.8747\n",
      "2025-07-25 22:22:55,901 - src.utils.notebook_setup - INFO - Evaluating Random Forest...\n",
      "2025-07-25 22:22:56,078 - src.utils.evaluate_utils - INFO - \n",
      "Random Forest Evaluation Results:\n",
      "2025-07-25 22:22:56,079 - src.utils.evaluate_utils - INFO - Accuracy: 1.0000\n",
      "2025-07-25 22:22:56,080 - src.utils.evaluate_utils - INFO - Precision: 1.0000\n",
      "2025-07-25 22:22:56,082 - src.utils.evaluate_utils - INFO - Recall: 1.0000\n",
      "2025-07-25 22:22:56,082 - src.utils.evaluate_utils - INFO - F1-Score: 1.0000\n",
      "2025-07-25 22:22:56,084 - src.utils.evaluate_utils - INFO - ROC-AUC: 1.0000\n",
      "2025-07-25 22:22:56,085 - src.utils.notebook_setup - INFO - Evaluating XGBoost...\n",
      "2025-07-25 22:22:56,136 - src.utils.evaluate_utils - INFO - \n",
      "XGBoost Evaluation Results:\n",
      "2025-07-25 22:22:56,137 - src.utils.evaluate_utils - INFO - Accuracy: 0.9977\n",
      "2025-07-25 22:22:56,138 - src.utils.evaluate_utils - INFO - Precision: 0.9958\n",
      "2025-07-25 22:22:56,140 - src.utils.evaluate_utils - INFO - Recall: 1.0000\n",
      "2025-07-25 22:22:56,141 - src.utils.evaluate_utils - INFO - F1-Score: 0.9979\n",
      "2025-07-25 22:22:56,142 - src.utils.evaluate_utils - INFO - ROC-AUC: 1.0000\n",
      "2025-07-25 22:22:56,145 - src.utils.notebook_setup - INFO - \n",
      "=== MODEL COMPARISON ===\n",
      "2025-07-25 22:22:56,147 - src.utils.notebook_setup - INFO -             model_name  accuracy  precision  recall  f1_score  roc_auc\n",
      "0                  SVM    0.8393     0.8504  0.8612    0.8557      NaN\n",
      "1  Logistic Regression    0.8005     0.8089  0.8373    0.8229   0.8747\n",
      "2        Random Forest    1.0000     1.0000  1.0000    1.0000   1.0000\n",
      "3              XGBoost    0.9977     0.9958  1.0000    0.9979   1.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.850416</td>\n",
       "      <td>0.861150</td>\n",
       "      <td>0.855749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800466</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.837307</td>\n",
       "      <td>0.822881</td>\n",
       "      <td>0.874692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.995810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997901</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  accuracy  precision    recall  f1_score   roc_auc\n",
       "0                  SVM  0.839286   0.850416  0.861150  0.855749       NaN\n",
       "1  Logistic Regression  0.800466   0.808943  0.837307  0.822881  0.874692\n",
       "2        Random Forest  1.000000   1.000000  1.000000  1.000000  1.000000\n",
       "3              XGBoost  0.997671   0.995810  1.000000  0.997901  1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATE ALL TRAINED MODELS\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    logger.info(f\"Evaluating {model_name}...\")\n",
    "    result = evaluate_model(model, X_test, y_test, model_name)\n",
    "    all_results.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "all_results_df = pd.DataFrame([\n",
    "    {k: v for k, v in result.items() if k != 'model'} \n",
    "    for result in all_results\n",
    "])\n",
    "\n",
    "logger.info(\"\\n=== MODEL COMPARISON ===\")\n",
    "logger.info(all_results_df.round(4))\n",
    "\n",
    "all_results_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec732dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND BEST ONE\n",
    "best_model_idx = all_results_df['roc_auc'].idxmax()\n",
    "best_model_name = all_results_df.iloc[best_model_idx]['model_name']\n",
    "best_model = all_results[best_model_idx]['model']\n",
    "\n",
    "\n",
    "\n",
    "logger.info(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "logger.info(f\"ROC-AUC: {all_results_df.iloc[best_model_idx]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE BEST MODEL TO DISK!\n",
    "from joblib import dump as dump_model\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Clear worse models\n",
    "clear_worse_models(best_model_name)\n",
    "\n",
    "# Save the winner as the final production model\n",
    "dump_model(best_model, \"../models/heart_disease_classifier.joblib\")\n",
    "\n",
    "best_result = all_results_df.iloc[best_model_idx]\n",
    "\n",
    "\n",
    "# Construct metadata dictionary\n",
    "model_metadata = {\n",
    "    \"model_name\": best_model_name,\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"algorithm\": type(best_model).__name__,\n",
    "    \"features\": list(X.columns),\n",
    "    \"target\": \"target\",\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": best_result[\"accuracy\"],\n",
    "        \"precision\": best_result[\"precision\"],\n",
    "        \"recall\": best_result[\"recall\"],\n",
    "        \"f1_score\": best_result[\"f1_score\"],\n",
    "        \"roc_auc\": best_result[\"roc_auc\"]\n",
    "    },\n",
    "    \"training_data_size\": len(X_train),\n",
    "    \"test_data_size\": len(X_test)\n",
    "}\n",
    "\n",
    "# Save to model_metadata.json\n",
    "logger.info(\"SAVING MODEL METADATA\")   \n",
    "with open(\"../models/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "\n",
    "logger.info(f\"Saved final model: {best_model_name} as heart_disease_classifier.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
